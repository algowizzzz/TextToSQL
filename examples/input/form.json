{
  "mode": "parquet",
  
  "schema": {
    "relationship": "ccr_limits (1) ←→ (N) trades via adaptiv_code",
    "tables": {
      "ccr_limits": {
        "entity": "Counterparty credit exposure aggregates (one row per counterparty per date)",
        "columns": {
          "adaptiv_code": "Primary key: Unique counterparty identifier (FK to trades)",
          "customer_name": "Counterparty legal name",
          "exposure_epe": "Expected Positive Exposure (average future exposure)",
          "exposure_pfe": "Potential Future Exposure (worst-case at confidence level)",
          "exposure_ead": "Exposure at Default (regulatory capital measure)",
          "limit_ccr": "Approved credit limit for counterparty",
          "limit_buffer": "Headroom: limit_ccr - exposure_pfe",
          "limit_utilization_pct": "Utilization percentage: (exposure_pfe / limit_ccr) * 100. >100 = BREACH",
          "currency": "Reporting currency (USD/CAD)",
          "booking_location": "Trading location (TOR/NYC/LDN/HKG/SYD)",
          "portfolio": "Risk portfolio (FX-Derivs/Rates/Commodities/Credit/Equities)",
          "risk_owner": "Responsible desk",
          "as_of_date": "Business date (VARCHAR, use CAST for comparisons)"
        }
      },
      "trades": {
        "entity": "Individual trade positions (many rows per counterparty)",
        "columns": {
          "trade_id": "Primary key: Unique trade identifier",
          "adaptiv_code": "Foreign key: Links to ccr_limits.adaptiv_code",
          "product": "Trade product type (FX FWD/IRS/CDS/etc)",
          "notional": "Trade notional amount",
          "mtm": "Mark-to-Market value (current P&L)",
          "asset_class": "FX/Rates/Commodities/Credit/Equities",
          "desk": "Trading desk",
          "book": "Trading book code",
          "trade_date": "Trade execution date",
          "maturity_date": "Trade maturity date",
          "counterparty": "Counterparty name (same as customer_name in ccr_limits)",
          "netting_set": "ISDA netting agreement ID",
          "csa_flag": "Credit Support Annex exists (boolean)",
          "collateralized": "Trade is collateralized (boolean)",
          "risk_factor": "Primary risk factor",
          "delta": "Price sensitivity",
          "gamma": "Delta sensitivity (convexity)",
          "vega": "Volatility sensitivity",
          "pnl": "Profit and loss",
          "currency": "Trade currency",
          "failed_trade": "Exposure calc failed, exposure = notional (overstated)",
          "as_of_date": "Business date (VARCHAR, use CAST for comparisons)"
        }
      }
    },
    "constraints": {
      "join": "ccr_limits.adaptiv_code = trades.adaptiv_code",
      "date_filter": "CAST(as_of_date AS DATE) for comparisons (stored as VARCHAR)",
      "column_ownership": {
        "limit_utilization_pct": "ONLY in ccr_limits",
        "exposure_*": "ONLY in ccr_limits",
        "limit_*": "ONLY in ccr_limits",
        "trade_id": "ONLY in trades",
        "product": "ONLY in trades",
        "mtm": "ONLY in trades",
        "notional": "ONLY in trades",
        "failed_trade": "ONLY in trades",
        "adaptiv_code": "In BOTH tables (join key)",
        "as_of_date": "In BOTH tables",
        "currency": "In BOTH tables"
      }
    }
  },
  
  "tables": {
    "ccr_limits": {
      "description": "CCR exposure vs limits by counterparty",
      "columns": [
        "adaptiv_code", "customer_name", "exposure_epe", "exposure_pfe", "exposure_ead",
        "limit_ccr", "limit_buffer", "limit_utilization_pct", "currency", "booking_location",
        "portfolio", "risk_owner", "as_of_date"
      ],
      "source": {
        "file_path": "input/data/ccr_limits.parquet"
      }
    },
    "trades": {
      "description": "Trade-level data for customers with limits. NOTE: failed_trade=true indicates exposure calculation failed; exposure is conservatively set equal to notional (overstated fallback).",
      "columns": [
        "trade_id", "adaptiv_code", "product", "notional", "mtm", "asset_class",
        "desk", "book", "trade_date", "maturity_date", "counterparty", "netting_set",
        "csa_flag", "collateralized", "risk_factor", "delta", "gamma", "vega", "pnl", "currency",
        "failed_trade", "as_of_date"
      ],
      "source": {
        "file_path": "input/data/trades.parquet"
      }
    }
  },
  
  "vocabulary": {
    "adaptiv code": "adaptiv_code",
    "utilization": "limit_utilization_pct",
    "limit utilization": "limit_utilization_pct",
    "counterparty code": "adaptiv_code",
    "breach": "limit_utilization_pct > 100",
    "breaches": "limit_utilization_pct > 100",
    "headroom": "limit_ccr - exposure_pfe",
    "mark to market": "mtm",
    "mark-to-market": "mtm",
    "notional amount": "notional",
    "failed": "failed_trade = true",
    "failed exposure": "failed_trade = true (exposure calculation failed, set to notional)",
    "overstated exposure": "failed_trade = true (conservative fallback)",
    "latest": "as_of_date = (SELECT MAX(as_of_date) FROM ccr_limits)",
    "recent": "CAST(as_of_date AS DATE) >= CURRENT_DATE - INTERVAL 7 DAYS"
  },
  
  "limits": {
    "default_limit": 200,
    "hard_max_rows": 1000,
    "allow_non_select": false,
    "timeout_seconds": 30
  },
  
  "prompts": {
    "dialect_hint": "DuckDB SQL",
    "system": "You are a senior data analyst who writes safe, efficient SQL for {dialect_hint}. Use ONLY the provided tables/columns. Use qualified names. Only JOIN tables when columns from BOTH tables are needed. Return a single runnable SQL statement. No commentary.\n\nENTITY RELATIONSHIPS:\n- ccr_limits (1) ←→ (N) trades via adaptiv_code\n- ccr_limits: Counterparty-level aggregates (exposure, limits)\n- trades: Trade-level details (products, MTM, greeks)\n\nCOLUMN OWNERSHIP (CRITICAL):\n- limit_utilization_pct, exposure_*, limit_*: ONLY in ccr_limits\n- trade_id, product, mtm, notional, failed_trade: ONLY in trades  \n- adaptiv_code, as_of_date, currency: In BOTH tables\n\nDATA TYPES:\n- as_of_date is VARCHAR: ALWAYS use CAST(as_of_date AS DATE) for comparisons\n\nBUSINESS RULES:\n- failed_trade=true means exposure calculation failed; exposure is conservatively set equal to notional (overstated).",
    "user_template": "SCHEMA:\n{schema_text}\n\nVOCABULARY (synonyms → canonical):\n{vocabulary}\n\nTASK:\nWrite a single {dialect_hint} SQL statement for this request:\n\"{user_request}\"\n\nCRITICAL CONSTRAINTS:\n- limit_utilization_pct is ONLY in ccr_limits, NOT in trades\n- exposure_* columns are ONLY in ccr_limits\n- mtm, notional, product, failed_trade are ONLY in trades\n- as_of_date is VARCHAR: use CAST(as_of_date AS DATE) for date comparisons\n\nJOIN RULES (IMPORTANT):\n- If ALL columns you need are in ONE table, do NOT join - query that single table\n- Only JOIN when you need columns from BOTH ccr_limits AND trades\n- When joining: ccr_limits.adaptiv_code = trades.adaptiv_code\n\nRULES:\n- Use ONLY tables/columns in SCHEMA\n- Use vocabulary mappings when available\n- If sampling implied, apply LIMIT {default_limit}\n- SELECT/CTEs only (no writes)\n- Return SQL ONLY, no explanations"
  },
  
  "model": {
    "provider": "openai",
    "name": "o1-mini",
    "_comment": "Reasoning models: o1-mini (recommended), o1, o1-preview. Standard models: gpt-4o-mini, gpt-4o, gpt-4-turbo. Note: o1 models ignore temperature (fixed at 1.0) and auto-combine system+user prompts.",
    "temperature": 0.0
  },
  
  "commentary": {
    "enabled": true,
    "max_rows_in_prompt": 20,
    "system_prompt": "You are a data analyst. Provide factual insights using ONLY the data shown. No speculation. Each statement must cite specific numbers.\n\nBUSINESS CONTEXT:\n- failed_trade=true: Exposure calculation failed, conservatively set to notional (overstated).",
    "user_template": "USER ASKED: \"{user_request}\"\n\nDATA ({row_count} rows, showing first {sample_size}):\nColumns: {columns}\n{data_preview}\n\nProvide 2-4 concise bullet points that DIRECTLY ANSWER the question. Each bullet: cite specific numbers and explain what they mean in context. No generic statements."
  },
  
  "optimization": {
    "two_stage_optimizer": true,
    "_comment": "Two-stage: Extract filters first (cheap), then generate SQL. Reduces LLM costs 30-50% and improves query performance."
  },
  
  "reference_values": {
    "enabled": true,
    "max_values_per_column": 20,
    "_comment": "Extract unique values from these columns to provide LLM with actual data context (auto-loaded from parquet at runtime)",
    "tables": {
      "ccr_limits": {
        "columns": ["customer_name", "portfolio", "booking_location", "as_of_date"]
      },
      "trades": {
        "columns": ["product", "counterparty", "asset_class", "desk", "as_of_date"]
      }
    }
  },
  
  "agent": {
    "enabled": false,
    "_comment": "LangGraph multi-turn agent with self-correction (use json_sql_agent.py --agent)",
    "max_turns": 5,
    "system_prompt": "You are an expert SQL analyst. Generate accurate SQL for the user's question. Return ONLY the SQL query, no explanations or markdown. If refining based on feedback, return ONLY the corrected SQL query.\n\nKEY RULES:\n- Use qualified names. Only JOIN tables when columns from BOTH tables are needed\n- If ALL columns needed are in ONE table, do NOT join - query that single table\n- Column ownership: limit_utilization_pct/exposure_*/limit_* ONLY in ccr_limits; trade_id/product/mtm/notional/failed_trade ONLY in trades\n- ALWAYS include filter columns in SELECT so results are verifiable (e.g., if WHERE failed_trade=true, SELECT failed_trade)\n- Use LIKE patterns for text filtering (e.g., product LIKE '%FWD%' instead of product = 'fwd')",
    "exit_node": {
      "system_prompt": "You are a SQL quality evaluator. Determine if the query results adequately answer the user's question. Be critical and check for missing columns or incomplete filters.",
      "user_template": "USER ASKED: \"{user_request}\"\n\nSQL EXECUTED:\n{sql}\n\nRESULTS ({row_count} rows, showing first 5):\n{data_preview}\n\nEvaluate critically:\n1. Does the SQL have ALL filters mentioned in the user's request?\n2. Are filter columns (from WHERE clause) included in SELECT for verification?\n3. Do the results actually answer the question?\n4. Are there any logic errors (wrong columns, missing conditions, etc.)?\n5. If 0 results and using exact text match (= 'value'), should it use LIKE '%value%' instead?\n\nRespond with ONE of:\n- 'GOOD' if results adequately answer the question AND SQL is complete\n- 'REFINE: <specific issue>' if query needs correction (e.g., use LIKE instead of =, missing filter, missing column in SELECT, wrong table, unnecessary join)\n- 'EMPTY: <reason>' if zero results seem legitimately correct (no data exists)"
    },
    "refinement_template": "PREVIOUS ATTEMPT:\nSQL: {previous_sql}\nResults: {row_count} rows\n\nISSUE IDENTIFIED:\n{feedback}\n\nRefine the SQL to fix this issue. Remember:\n- Schema: {schema_hint}\n- Column ownership: limit_utilization_pct is ONLY in ccr_limits, mtm/notional/failed_trade are ONLY in trades\n- JOIN ONLY if you need columns from BOTH tables; otherwise query the single table directly\n- ALWAYS include filter columns in SELECT (e.g., if WHERE product LIKE '%FWD%', include product in SELECT)\n- Apply ALL user-specified filters (don't drop conditions from previous attempts)",
    "fallback_message": "Max refinement turns ({max_turns}) reached. Returning best attempt."
  },
  
  "rule_based_queries": {
    "top breaches headroom": "SELECT l.adaptiv_code, l.customer_name, l.exposure_pfe, l.limit_ccr, (l.limit_ccr - l.exposure_pfe) AS headroom, l.limit_utilization_pct FROM ccr_limits l WHERE l.limit_utilization_pct > 100 ORDER BY l.limit_utilization_pct DESC LIMIT 200",
    "top trades by mtm for breaches": "WITH breaching AS (SELECT adaptiv_code FROM ccr_limits WHERE limit_utilization_pct > 100) SELECT t.adaptiv_code, t.trade_id, t.product, t.mtm FROM trades t JOIN breaching b ON b.adaptiv_code = t.adaptiv_code QUALIFY ROW_NUMBER() OVER (PARTITION BY t.adaptiv_code ORDER BY ABS(t.mtm) DESC) <= 3 ORDER BY t.adaptiv_code LIMIT 200",
    "portfolio utilization summary": "SELECT portfolio, booking_location, SUM(exposure_epe) AS total_epe, COUNT(DISTINCT adaptiv_code) AS counterparties, AVG(limit_utilization_pct) AS avg_utilization FROM ccr_limits GROUP BY 1,2 ORDER BY total_epe DESC LIMIT 200",
    "failed trades": "SELECT trade_id, counterparty, product, notional, as_of_date FROM trades WHERE failed_trade = true ORDER BY as_of_date DESC LIMIT 200",
    "breach trend": "SELECT as_of_date, COUNT(*) as breach_count, AVG(limit_utilization_pct) as avg_util FROM ccr_limits WHERE limit_utilization_pct > 100 GROUP BY as_of_date ORDER BY as_of_date DESC LIMIT 200",
    "daily trade volume": "SELECT as_of_date, COUNT(*) as trade_count, SUM(notional) as total_notional, SUM(CASE WHEN failed_trade THEN 1 ELSE 0 END) as failed_count FROM trades GROUP BY as_of_date ORDER BY as_of_date DESC LIMIT 200"
  }
}

